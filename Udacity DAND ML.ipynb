{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn GaussianNB example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "print(clf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: GaussianNB deployment on terrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ClassifyNB.py: \n",
    "def classify(features_train, labels_train):   \n",
    "    ### import the sklearn module for GaussianNB\n",
    "    ### create classifier\n",
    "    ### fit the classifier on the training features and labels\n",
    "    ### return the fit classifier\n",
    "    \n",
    "    \n",
    "    ### your code goes here!\n",
    "    import numpy as np\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    return clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_terrain_data.py\n",
    "\n",
    "#!/usr/bin/python\n",
    "import random\n",
    "\n",
    "\n",
    "def makeTerrainData(n_points=1000):\n",
    "###############################################################################\n",
    "### make the toy dataset\n",
    "    random.seed(42)\n",
    "    grade = [random.random() for ii in range(0,n_points)]\n",
    "    bumpy = [random.random() for ii in range(0,n_points)]\n",
    "    error = [random.random() for ii in range(0,n_points)]\n",
    "    y = [round(grade[ii]*bumpy[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]\n",
    "    for ii in range(0, len(y)):\n",
    "        if grade[ii]>0.8 or bumpy[ii]>0.8:\n",
    "            y[ii] = 1.0\n",
    "\n",
    "### split into train/test sets\n",
    "    X = [[gg, ss] for gg, ss in zip(grade, bumpy)]\n",
    "    split = int(0.75*n_points)\n",
    "    X_train = X[0:split]\n",
    "    X_test  = X[split:]\n",
    "    y_train = y[0:split]\n",
    "    y_test  = y[split:]\n",
    "\n",
    "    grade_sig = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
    "    bumpy_sig = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
    "    grade_bkg = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
    "    bumpy_bkg = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
    "\n",
    "#    training_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
    "#            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
    "\n",
    "\n",
    "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "\n",
    "    test_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
    "            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "#    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_vis.py\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "#from udacityplots import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib \n",
    "matplotlib.use('agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.ioff()\n",
    "\n",
    "def prettyPicture(clf, X_test, y_test):\n",
    "    x_min = 0.0; x_max = 1.0\n",
    "    y_min = 0.0; y_max = 1.0\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    h = .01  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=pl.cm.seismic)\n",
    "\n",
    "    # Plot also the test points\n",
    "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "\n",
    "    plt.scatter(grade_sig, bumpy_sig, color = \"b\", label=\"fast\")\n",
    "    plt.scatter(grade_bkg, bumpy_bkg, color = \"r\", label=\"slow\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"bumpiness\")\n",
    "    plt.ylabel(\"grade\")\n",
    "\n",
    "    plt.savefig(\"test.png\")\n",
    "    \n",
    "import base64\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "def output_image(name, format, bytes):\n",
    "    image_start = \"BEGIN_IMAGE_f9825uweof8jw9fj4r8\"\n",
    "    image_end = \"END_IMAGE_0238jfw08fjsiufhw8frs\"\n",
    "    data = {}\n",
    "    data['name'] = name\n",
    "    data['format'] = format\n",
    "    data['bytes'] = base64.encodestring(bytes)\n",
    "    print image_start+json.dumps(data)+image_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named prep_terrain_data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5899f51c6b40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprep_terrain_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmakeTerrainData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mclass_vis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprettyPicture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mClassifyNB\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named prep_terrain_data"
     ]
    }
   ],
   "source": [
    "# studentMain.py\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" Complete the code in ClassifyNB.py with the sklearn\n",
    "    Naive Bayes classifier to classify the terrain data.\n",
    "    \n",
    "    The objective of this exercise is to recreate the decision \n",
    "    boundary found in the lesson video, and make a plot that\n",
    "    visually shows the decision boundary \"\"\"\n",
    "\n",
    "\n",
    "from prep_terrain_data import makeTerrainData\n",
    "from class_vis import prettyPicture, output_image\n",
    "from ClassifyNB import classify\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "### the training data (features_train, labels_train) have both \"fast\" and \"slow\" points mixed\n",
    "### in together--separate them so we can give them different colors in the scatterplot,\n",
    "### and visually identify them\n",
    "grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "\n",
    "\n",
    "# You will need to complete this function imported from the ClassifyNB script.\n",
    "# Be sure to change to that code tab to complete this quiz.\n",
    "clf = classify(features_train, labels_train)\n",
    "\n",
    "### draw the decision boundary with the text points overlaid\n",
    "prettyPicture(clf, features_test, labels_test)\n",
    "output_image(\"test.png\", \"png\", open(\"test.png\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn accuracy_score example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "\n",
    "print accuracy_score(y_true, y_pred)\n",
    "print accuracy_score(y_true, y_pred, normalize=False) \n",
    "# normalize: \n",
    "# If =False, return the number of correctly classified samples. \n",
    "# Otherwise, return the fraction of correctly classified samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Calculating NB accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# method 1: \"sklearn accuracy_score\"\n",
    "\n",
    "def NBAccuracy(features_train, labels_train, features_test, labels_test):\n",
    "    \"\"\" compute the accuracy of your Naive Bayes classifier \"\"\"\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "\n",
    "    ### calculate and return the accuracy on the test data\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(labels_test, pred, normalize = True)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method 2: .score\n",
    "\n",
    "def NBAccuracy(features_train, labels_train, features_test, labels_test):\n",
    "    \"\"\" compute the accuracy of your Naive Bayes classifier \"\"\"\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    \n",
    "    ### calculate and return the accuracy on the test data:\n",
    "    accuracy = clf.score(features_test, labels_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8f9035de1600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)  \n",
    "\n",
    "# After being fitted, the model can then be used to predict new values:\n",
    "pred = clf.predict([[2., 2.]])\n",
    "\n",
    "print plot(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Coding up the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named class_vis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-314894e37842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mclass_vis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprettyPicture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprep_terrain_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmakeTerrainData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named class_vis"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from class_vis import prettyPicture\n",
    "from prep_terrain_data import makeTerrainData\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "########################## SVM #################################\n",
    "### we handle the import statement and SVC creation for you here\n",
    "from sklearn.svm import SVC # SVC: support vector classifier\n",
    "clf = SVC(kernel=\"linear\") # using kernal function \"linear\"\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred, labels_test)\n",
    "\n",
    "def submitAccuracy():\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-55aaf9d8b7a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "X = [[0,0], [1,1]]\n",
    "Y = [0,1]\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X,Y)\n",
    "\n",
    "clf.predict([[2.,2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named class_vis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7d0ca417c027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mclass_vis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprettyPicture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprep_terrain_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmakeTerrainData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named class_vis"
     ]
    }
   ],
   "source": [
    "# studentMain.py\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" lecture and example code for decision tree unit \"\"\"\n",
    "\n",
    "import sys\n",
    "from class_vis import prettyPicture, output_image\n",
    "from prep_terrain_data import makeTerrainData\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from classifyDT import classify\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "\n",
    "\n",
    "### the classify() function in classifyDT is where the magic\n",
    "### happens--fill in this function in the file 'classifyDT.py'!\n",
    "clf = classify(features_train, labels_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### grader code, do not modify below this line\n",
    "\n",
    "prettyPicture(clf, features_test, labels_test)\n",
    "output_image(\"test.png\", \"png\", open(\"test.png\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifyDT.py\n",
    "\n",
    "def classify(features_train, labels_train):\n",
    "    \n",
    "    ### your code goes here--should return a trained decision tree classifer\n",
    "    from sklearn import tree\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(features_train, labels_train)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named class_vis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-10ea2d07ebdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mclass_vis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprettyPicture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprep_terrain_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmakeTerrainData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named class_vis"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from class_vis import prettyPicture\n",
    "from prep_terrain_data import makeTerrainData\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "########################## DECISION TREE #################################\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "### you fill this in!\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(labels_test, pred, normalize = True)\n",
    "### be sure to compute the accuracy on the test set\n",
    "    \n",
    "def submitAccuracies():\n",
    "    return {\"acc\":round(acc,3)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree accuracy with different min_samples_split parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named class_vis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-91f31a57d311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mclass_vis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprettyPicture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprep_terrain_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmakeTerrainData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named class_vis"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from class_vis import prettyPicture\n",
    "from prep_terrain_data import makeTerrainData\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "\n",
    "########################## DECISION TREE #################################\n",
    "\n",
    "### your code goes here--now create 2 decision tree classifiers,\n",
    "### one with min_samples_split=2 and one with min_samples_split=50\n",
    "### compute the accuracies on the testing data and store\n",
    "### the accuracy numbers to acc_min_samples_split_2 and\n",
    "### acc_min_samples_split_50, respectively\n",
    "from sklearn import tree\n",
    "clf_20 = tree.DecisionTreeClassifier(min_samples_split = 2)\n",
    "clf_20.fit(features_train, labels_train)\n",
    "pred_20 = clf_20.predict(features_test)\n",
    "\n",
    "clf_50 = tree.DecisionTreeClassifier(min_samples_split = 50)\n",
    "clf_50.fit(features_train, labels_train)\n",
    "pred_50 = clf_50.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_min_samples_split_2 = accuracy_score(labels_test, pred_20)\n",
    "acc_min_samples_split_50 = accuracy_score(labels_test, pred_50)\n",
    "\n",
    "\n",
    "def submitAccuracies():\n",
    "    return {\"acc_min_samples_split_2\":round(acc_min_samples_split_2,3),\n",
    "          \"acc_min_samples_split_50\":round(acc_min_samples_split_50,3)}\n",
    "\n",
    "### output: {'acc_min_samples_split_50': 0.912, 'acc_min_samples_split_2': 0.908}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1, **kwargs)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from prep_terrain_data import makeTerrainData\n",
    "from class_vis import prettyPicture\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "\n",
    "### the training data (features_train, labels_train) have both \"fast\" and \"slow\"\n",
    "### points mixed together--separate them so we can give them different colors\n",
    "### in the scatterplot and identify them visually\n",
    "grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "\n",
    "\n",
    "#### initial visualization\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.scatter(bumpy_fast, grade_fast, color = \"b\", label=\"fast\")\n",
    "plt.scatter(grade_slow, bumpy_slow, color = \"r\", label=\"slow\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"bumpiness\")\n",
    "plt.ylabel(\"grade\")\n",
    "################################################################################\n",
    "\n",
    "### your code here!  name your classifier object clf if you want the \n",
    "### visualization code (prettyPicture) to show you the decision boundary\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors = 10, weights = 'distance')\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "print acc\n",
    "\n",
    "\n",
    "try:\n",
    "    prettyPicture(clf, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from prep_terrain_data import makeTerrainData\n",
    "from class_vis import prettyPicture\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "\n",
    "### the training data (features_train, labels_train) have both \"fast\" and \"slow\"\n",
    "### points mixed together--separate them so we can give them different colors\n",
    "### in the scatterplot and identify them visually\n",
    "grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "\n",
    "\n",
    "#### initial visualization\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.scatter(bumpy_fast, grade_fast, color = \"b\", label=\"fast\")\n",
    "plt.scatter(grade_slow, bumpy_slow, color = \"r\", label=\"slow\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"bumpiness\")\n",
    "plt.ylabel(\"grade\")\n",
    "################################################################################\n",
    "\n",
    "### your code here!  name your classifier object clf if you want the \n",
    "### visualization code (prettyPicture) to show you the decision boundary\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 10, criterion = 'gini',\n",
    "                             max_features = 'auto', max_depth = None, min_samples_split = 2)\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "print acc\n",
    "\n",
    "\n",
    "try:\n",
    "    prettyPicture(clf, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost (Adaptive Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.ensemble.AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)[source]Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from prep_terrain_data import makeTerrainData\n",
    "from class_vis import prettyPicture\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "\n",
    "### the training data (features_train, labels_train) have both \"fast\" and \"slow\"\n",
    "### points mixed together--separate them so we can give them different colors\n",
    "### in the scatterplot and identify them visually\n",
    "grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "\n",
    "\n",
    "#### initial visualization\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.scatter(bumpy_fast, grade_fast, color = \"b\", label=\"fast\")\n",
    "plt.scatter(grade_slow, bumpy_slow, color = \"r\", label=\"slow\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"bumpiness\")\n",
    "plt.ylabel(\"grade\")\n",
    "################################################################################\n",
    "\n",
    "### your code here!  name your classifier object clf if you want the \n",
    "### visualization code (prettyPicture) to show you the decision boundary\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators = 50, learning_rate = 1.0,\n",
    "                         algorithm = 'SAMME.R', random_state = None)\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "print acc\n",
    "\n",
    "try:\n",
    "    prettyPicture(clf, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
